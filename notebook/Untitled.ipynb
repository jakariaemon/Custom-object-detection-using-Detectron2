{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980825fa-9a66-479c-a93d-3d37db7aa41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:32:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:32:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:32:52 d2.data.datasets.coco]: \u001b[0mLoaded 1826 images in COCO format from train.json\n",
      "\u001b[32m[03/04 17:32:52 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1826 images left.\n",
      "\u001b[32m[03/04 17:32:52 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   drone    | 1832         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/04 17:32:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 17:32:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 17:32:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/04 17:32:52 d2.data.common]: \u001b[0mSerializing 1826 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:32:52 d2.data.common]: \u001b[0mSerialized dataset takes 5.81 MiB\n",
      "\u001b[32m[03/04 17:32:52 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[03/04 17:32:52 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:32:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emon/.local/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:33:01 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 19  total_loss: 2.057  loss_cls: 0.3429  loss_box_reg: 0.9732  loss_mask: 0.6837  loss_rpn_cls: 0.0007385  loss_rpn_loc: 0.004262    time: 0.3630  last_time: 0.3724  data_time: 0.0169  last_data_time: 0.0034   lr: 6.9467e-05  max_mem: 1639M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:33:03.130089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:33:12 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 39  total_loss: 1.201  loss_cls: 0.1037  loss_box_reg: 0.6719  loss_mask: 0.3558  loss_rpn_cls: 0.0004404  loss_rpn_loc: 0.006151    time: 0.3710  last_time: 0.3787  data_time: 0.0035  last_data_time: 0.0035   lr: 0.00014175  max_mem: 1639M\n",
      "\u001b[32m[03/04 17:33:19 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 59  total_loss: 0.6734  loss_cls: 0.06037  loss_box_reg: 0.4166  loss_mask: 0.1944  loss_rpn_cls: 0.0001401  loss_rpn_loc: 0.004081    time: 0.3678  last_time: 0.3683  data_time: 0.0040  last_data_time: 0.0036   lr: 0.00021403  max_mem: 1639M\n",
      "\u001b[32m[03/04 17:33:26 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 79  total_loss: 0.6853  loss_cls: 0.07796  loss_box_reg: 0.4367  loss_mask: 0.1628  loss_rpn_cls: 0.0004354  loss_rpn_loc: 0.004412    time: 0.3656  last_time: 0.3525  data_time: 0.0034  last_data_time: 0.0031   lr: 0.00028631  max_mem: 1655M\n",
      "\u001b[32m[03/04 17:33:33 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 99  total_loss: 0.6975  loss_cls: 0.09548  loss_box_reg: 0.4416  loss_mask: 0.1799  loss_rpn_cls: 4.339e-05  loss_rpn_loc: 0.004393    time: 0.3617  last_time: 0.2775  data_time: 0.0037  last_data_time: 0.0041   lr: 0.00035859  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:33:40 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 119  total_loss: 0.6696  loss_cls: 0.06306  loss_box_reg: 0.4107  loss_mask: 0.1796  loss_rpn_cls: 0.0006596  loss_rpn_loc: 0.00422    time: 0.3612  last_time: 0.3688  data_time: 0.0034  last_data_time: 0.0035   lr: 0.00043087  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:33:47 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 139  total_loss: 0.7124  loss_cls: 0.09172  loss_box_reg: 0.4339  loss_mask: 0.1517  loss_rpn_cls: 0.0008827  loss_rpn_loc: 0.005747    time: 0.3611  last_time: 0.3356  data_time: 0.0038  last_data_time: 0.0032   lr: 0.00050315  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:33:55 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 159  total_loss: 0.6449  loss_cls: 0.07038  loss_box_reg: 0.3975  loss_mask: 0.165  loss_rpn_cls: 0.0007148  loss_rpn_loc: 0.004498    time: 0.3604  last_time: 0.3574  data_time: 0.0037  last_data_time: 0.0032   lr: 0.00057543  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:34:01 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 179  total_loss: 0.5828  loss_cls: 0.06565  loss_box_reg: 0.3838  loss_mask: 0.1326  loss_rpn_cls: 0.0004686  loss_rpn_loc: 0.004526    time: 0.3586  last_time: 0.3618  data_time: 0.0041  last_data_time: 0.0036   lr: 0.00064771  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:34:08 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 199  total_loss: 0.5648  loss_cls: 0.07183  loss_box_reg: 0.3627  loss_mask: 0.1358  loss_rpn_cls: 0.0002279  loss_rpn_loc: 0.003657    time: 0.3580  last_time: 0.3769  data_time: 0.0038  last_data_time: 0.0054   lr: 0.00071999  max_mem: 1660M\n",
      "\u001b[32m[03/04 17:34:15 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 219  total_loss: 0.6635  loss_cls: 0.09956  loss_box_reg: 0.3725  loss_mask: 0.1536  loss_rpn_cls: 0.001948  loss_rpn_loc: 0.01262    time: 0.3573  last_time: 0.3597  data_time: 0.0037  last_data_time: 0.0030   lr: 0.000709  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:23 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 239  total_loss: 1.305  loss_cls: 0.2325  loss_box_reg: 0.2947  loss_mask: 0.31  loss_rpn_cls: 0.164  loss_rpn_loc: 0.04538    time: 0.3573  last_time: 0.3607  data_time: 0.0039  last_data_time: 0.0034   lr: 0.00069245  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:30 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 259  total_loss: 1.48  loss_cls: 0.2737  loss_box_reg: 0.2542  loss_mask: 0.5551  loss_rpn_cls: 0.1964  loss_rpn_loc: 0.04359    time: 0.3568  last_time: 0.3401  data_time: 0.0038  last_data_time: 0.0038   lr: 0.00067473  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:36 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 279  total_loss: 1.249  loss_cls: 0.1928  loss_box_reg: 0.2942  loss_mask: 0.3474  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.03691    time: 0.3553  last_time: 0.3415  data_time: 0.0034  last_data_time: 0.0033   lr: 0.00065594  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:43 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 299  total_loss: 1.291  loss_cls: 0.3071  loss_box_reg: 0.665  loss_mask: 0.3047  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.01123    time: 0.3541  last_time: 0.3331  data_time: 0.0034  last_data_time: 0.0041   lr: 0.00063613  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:50 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 319  total_loss: 1.192  loss_cls: 0.2268  loss_box_reg: 0.6569  loss_mask: 0.2596  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01069    time: 0.3535  last_time: 0.3449  data_time: 0.0033  last_data_time: 0.0033   lr: 0.00061539  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:34:57 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 339  total_loss: 0.7892  loss_cls: 0.1141  loss_box_reg: 0.4438  loss_mask: 0.2025  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.00639    time: 0.3521  last_time: 0.3163  data_time: 0.0035  last_data_time: 0.0037   lr: 0.0005938  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:35:04 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 359  total_loss: 0.7266  loss_cls: 0.1163  loss_box_reg: 0.4135  loss_mask: 0.1782  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.006319    time: 0.3523  last_time: 0.3663  data_time: 0.0036  last_data_time: 0.0042   lr: 0.00057145  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:35:11 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 379  total_loss: 0.7724  loss_cls: 0.1186  loss_box_reg: 0.4094  loss_mask: 0.1775  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.008173    time: 0.3528  last_time: 0.3680  data_time: 0.0036  last_data_time: 0.0038   lr: 0.00054842  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:35:18 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 399  total_loss: 0.6186  loss_cls: 0.09222  loss_box_reg: 0.3539  loss_mask: 0.1594  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.007068    time: 0.3532  last_time: 0.3673  data_time: 0.0038  last_data_time: 0.0038   lr: 0.0005248  max_mem: 1661M\n",
      "\u001b[32m[03/04 17:35:25 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 419  total_loss: 0.5196  loss_cls: 0.0656  loss_box_reg: 0.2736  loss_mask: 0.1468  loss_rpn_cls: 0.008772  loss_rpn_loc: 0.009275    time: 0.3534  last_time: 0.3573  data_time: 0.0037  last_data_time: 0.0038   lr: 0.00050069  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:35:32 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 439  total_loss: 0.5661  loss_cls: 0.07564  loss_box_reg: 0.3381  loss_mask: 0.1295  loss_rpn_cls: 0.007257  loss_rpn_loc: 0.006655    time: 0.3534  last_time: 0.3574  data_time: 0.0045  last_data_time: 0.0159   lr: 0.00047619  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:35:39 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 459  total_loss: 0.5296  loss_cls: 0.06726  loss_box_reg: 0.3044  loss_mask: 0.123  loss_rpn_cls: 0.007178  loss_rpn_loc: 0.005834    time: 0.3530  last_time: 0.3361  data_time: 0.0041  last_data_time: 0.0041   lr: 0.00045138  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:35:46 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 479  total_loss: 0.4828  loss_cls: 0.07704  loss_box_reg: 0.257  loss_mask: 0.1227  loss_rpn_cls: 0.005681  loss_rpn_loc: 0.005921    time: 0.3523  last_time: 0.3205  data_time: 0.0039  last_data_time: 0.0041   lr: 0.00042637  max_mem: 1662M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:35:53 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:35:53 d2.data.datasets.coco]: \u001b[0mLoaded 384 images in COCO format from validation.json\n",
      "\u001b[32m[03/04 17:35:53 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   Object   | 387          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/04 17:35:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/04 17:35:53 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/04 17:35:53 d2.data.common]: \u001b[0mSerializing 384 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:35:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.21 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:35:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[03/04 17:35:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 384 batches\n",
      "\u001b[32m[03/04 17:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/384. Dataloading: 0.0012 s/iter. Inference: 0.1391 s/iter. Eval: 0.0256 s/iter. Total: 0.1659 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/04 17:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 40/384. Dataloading: 0.0014 s/iter. Inference: 0.1420 s/iter. Eval: 0.0289 s/iter. Total: 0.1724 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/04 17:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 70/384. Dataloading: 0.0013 s/iter. Inference: 0.1425 s/iter. Eval: 0.0269 s/iter. Total: 0.1709 s/iter. ETA=0:00:53\n",
      "\u001b[32m[03/04 17:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 102/384. Dataloading: 0.0013 s/iter. Inference: 0.1421 s/iter. Eval: 0.0230 s/iter. Total: 0.1665 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/04 17:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 136/384. Dataloading: 0.0013 s/iter. Inference: 0.1411 s/iter. Eval: 0.0198 s/iter. Total: 0.1623 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/04 17:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 172/384. Dataloading: 0.0013 s/iter. Inference: 0.1398 s/iter. Eval: 0.0166 s/iter. Total: 0.1578 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/04 17:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 208/384. Dataloading: 0.0013 s/iter. Inference: 0.1390 s/iter. Eval: 0.0144 s/iter. Total: 0.1548 s/iter. ETA=0:00:27\n",
      "\u001b[32m[03/04 17:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 236/384. Dataloading: 0.0013 s/iter. Inference: 0.1400 s/iter. Eval: 0.0170 s/iter. Total: 0.1584 s/iter. ETA=0:00:23\n",
      "\u001b[32m[03/04 17:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 267/384. Dataloading: 0.0013 s/iter. Inference: 0.1399 s/iter. Eval: 0.0179 s/iter. Total: 0.1592 s/iter. ETA=0:00:18\n",
      "\u001b[32m[03/04 17:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 303/384. Dataloading: 0.0013 s/iter. Inference: 0.1391 s/iter. Eval: 0.0164 s/iter. Total: 0.1569 s/iter. ETA=0:00:12\n",
      "\u001b[32m[03/04 17:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 339/384. Dataloading: 0.0013 s/iter. Inference: 0.1385 s/iter. Eval: 0.0154 s/iter. Total: 0.1552 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/04 17:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 375/384. Dataloading: 0.0013 s/iter. Inference: 0.1379 s/iter. Eval: 0.0147 s/iter. Total: 0.1540 s/iter. ETA=0:00:01\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:58.254164 (0.153705 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:52 (0.137813 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.599\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 52.661 | 98.992 | 47.944 | 0.000 | 55.524 | 47.630 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.843\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.687\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.713\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 63.685 | 98.992 | 84.312 | 0.000 | 66.697 | 57.059 |\n",
      "\u001b[32m[03/04 17:36:53 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: 52.6607,98.9918,47.9441,0.0000,55.5236,47.6296\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/04 17:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: 63.6853,98.9918,84.3121,0.0000,66.6968,57.0586\n",
      "\u001b[32m[03/04 17:36:53 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 499  total_loss: 0.4937  loss_cls: 0.05618  loss_box_reg: 0.2949  loss_mask: 0.1264  loss_rpn_cls: 0.005731  loss_rpn_loc: 0.007434    time: 0.3520  last_time: 0.3722  data_time: 0.0038  last_data_time: 0.0038   lr: 0.00040126  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:00 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 519  total_loss: 0.5674  loss_cls: 0.08529  loss_box_reg: 0.3031  loss_mask: 0.133  loss_rpn_cls: 0.002963  loss_rpn_loc: 0.006909    time: 0.3521  last_time: 0.3725  data_time: 0.0037  last_data_time: 0.0043   lr: 0.00037614  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:07 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 539  total_loss: 0.4988  loss_cls: 0.06115  loss_box_reg: 0.2899  loss_mask: 0.1329  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.007409    time: 0.3525  last_time: 0.3789  data_time: 0.0037  last_data_time: 0.0035   lr: 0.00035111  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:14 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 559  total_loss: 0.4675  loss_cls: 0.049  loss_box_reg: 0.2674  loss_mask: 0.1151  loss_rpn_cls: 0.003518  loss_rpn_loc: 0.005581    time: 0.3528  last_time: 0.3685  data_time: 0.0040  last_data_time: 0.0031   lr: 0.00032628  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:22 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 579  total_loss: 0.4612  loss_cls: 0.04922  loss_box_reg: 0.2922  loss_mask: 0.1157  loss_rpn_cls: 0.004244  loss_rpn_loc: 0.005369    time: 0.3532  last_time: 0.3794  data_time: 0.0039  last_data_time: 0.0030   lr: 0.00030174  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:29 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 599  total_loss: 0.4567  loss_cls: 0.0544  loss_box_reg: 0.2577  loss_mask: 0.1265  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.005724    time: 0.3538  last_time: 0.3690  data_time: 0.0039  last_data_time: 0.0035   lr: 0.00027759  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:36 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 619  total_loss: 0.4823  loss_cls: 0.03855  loss_box_reg: 0.299  loss_mask: 0.1245  loss_rpn_cls: 0.002914  loss_rpn_loc: 0.005962    time: 0.3538  last_time: 0.3648  data_time: 0.0041  last_data_time: 0.0035   lr: 0.00025392  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:43 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 639  total_loss: 0.4151  loss_cls: 0.04892  loss_box_reg: 0.2442  loss_mask: 0.1173  loss_rpn_cls: 0.003957  loss_rpn_loc: 0.005547    time: 0.3539  last_time: 0.3548  data_time: 0.0045  last_data_time: 0.0033   lr: 0.00023083  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:50 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 659  total_loss: 0.3891  loss_cls: 0.05196  loss_box_reg: 0.2151  loss_mask: 0.1025  loss_rpn_cls: 0.003721  loss_rpn_loc: 0.006052    time: 0.3538  last_time: 0.3506  data_time: 0.0046  last_data_time: 0.0039   lr: 0.0002084  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:37:57 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 679  total_loss: 0.4088  loss_cls: 0.05164  loss_box_reg: 0.2452  loss_mask: 0.1075  loss_rpn_cls: 0.003064  loss_rpn_loc: 0.007038    time: 0.3535  last_time: 0.3115  data_time: 0.0038  last_data_time: 0.0033   lr: 0.00018673  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:04 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 699  total_loss: 0.4152  loss_cls: 0.0419  loss_box_reg: 0.2351  loss_mask: 0.1089  loss_rpn_cls: 0.002569  loss_rpn_loc: 0.006133    time: 0.3537  last_time: 0.3732  data_time: 0.0038  last_data_time: 0.0035   lr: 0.0001659  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:11 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 719  total_loss: 0.4005  loss_cls: 0.036  loss_box_reg: 0.2265  loss_mask: 0.1073  loss_rpn_cls: 0.003477  loss_rpn_loc: 0.005871    time: 0.3537  last_time: 0.3776  data_time: 0.0042  last_data_time: 0.0035   lr: 0.000146  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:19 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 739  total_loss: 0.3773  loss_cls: 0.0453  loss_box_reg: 0.2228  loss_mask: 0.1019  loss_rpn_cls: 0.002755  loss_rpn_loc: 0.005316    time: 0.3538  last_time: 0.3743  data_time: 0.0040  last_data_time: 0.0034   lr: 0.0001271  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:26 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 759  total_loss: 0.3866  loss_cls: 0.03137  loss_box_reg: 0.2199  loss_mask: 0.1039  loss_rpn_cls: 0.002483  loss_rpn_loc: 0.005977    time: 0.3539  last_time: 0.3300  data_time: 0.0036  last_data_time: 0.0036   lr: 0.00010927  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:33 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 779  total_loss: 0.3828  loss_cls: 0.02877  loss_box_reg: 0.244  loss_mask: 0.09838  loss_rpn_cls: 0.001462  loss_rpn_loc: 0.004566    time: 0.3536  last_time: 0.3299  data_time: 0.0041  last_data_time: 0.0036   lr: 9.2597e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:40 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 799  total_loss: 0.3773  loss_cls: 0.03454  loss_box_reg: 0.2095  loss_mask: 0.1189  loss_rpn_cls: 0.001937  loss_rpn_loc: 0.007266    time: 0.3535  last_time: 0.3590  data_time: 0.0034  last_data_time: 0.0031   lr: 7.7133e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:46 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 819  total_loss: 0.3932  loss_cls: 0.04385  loss_box_reg: 0.21  loss_mask: 0.1125  loss_rpn_cls: 0.001881  loss_rpn_loc: 0.005395    time: 0.3533  last_time: 0.3301  data_time: 0.0037  last_data_time: 0.0037   lr: 6.2944e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:38:53 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 839  total_loss: 0.4032  loss_cls: 0.04082  loss_box_reg: 0.2348  loss_mask: 0.106  loss_rpn_cls: 0.00145  loss_rpn_loc: 0.005297    time: 0.3531  last_time: 0.3557  data_time: 0.0039  last_data_time: 0.0032   lr: 5.0084e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:00 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 859  total_loss: 0.3749  loss_cls: 0.04006  loss_box_reg: 0.2259  loss_mask: 0.09279  loss_rpn_cls: 0.002225  loss_rpn_loc: 0.004352    time: 0.3530  last_time: 0.3678  data_time: 0.0036  last_data_time: 0.0040   lr: 3.8606e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:08 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 879  total_loss: 0.3648  loss_cls: 0.03502  loss_box_reg: 0.2166  loss_mask: 0.09694  loss_rpn_cls: 0.0008465  loss_rpn_loc: 0.006187    time: 0.3532  last_time: 0.3747  data_time: 0.0038  last_data_time: 0.0036   lr: 2.8554e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:15 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 899  total_loss: 0.3464  loss_cls: 0.02739  loss_box_reg: 0.2004  loss_mask: 0.09656  loss_rpn_cls: 0.0006118  loss_rpn_loc: 0.004655    time: 0.3535  last_time: 0.3269  data_time: 0.0036  last_data_time: 0.0039   lr: 1.9968e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:22 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 919  total_loss: 0.3393  loss_cls: 0.03561  loss_box_reg: 0.2146  loss_mask: 0.09547  loss_rpn_cls: 0.0008048  loss_rpn_loc: 0.004806    time: 0.3536  last_time: 0.3826  data_time: 0.0051  last_data_time: 0.0113   lr: 1.2881e-05  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:29 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 939  total_loss: 0.3469  loss_cls: 0.03753  loss_box_reg: 0.1964  loss_mask: 0.09611  loss_rpn_cls: 0.0008524  loss_rpn_loc: 0.004578    time: 0.3537  last_time: 0.3326  data_time: 0.0057  last_data_time: 0.0042   lr: 7.3225e-06  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:36 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 959  total_loss: 0.3343  loss_cls: 0.03777  loss_box_reg: 0.1887  loss_mask: 0.09885  loss_rpn_cls: 0.002474  loss_rpn_loc: 0.003974    time: 0.3538  last_time: 0.3612  data_time: 0.0043  last_data_time: 0.0034   lr: 3.3136e-06  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:44 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 979  total_loss: 0.3455  loss_cls: 0.03825  loss_box_reg: 0.1856  loss_mask: 0.1024  loss_rpn_cls: 0.00148  loss_rpn_loc: 0.005275    time: 0.3538  last_time: 0.3668  data_time: 0.0046  last_data_time: 0.0032   lr: 8.7018e-07  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.3481  loss_cls: 0.04465  loss_box_reg: 0.2062  loss_mask: 0.1067  loss_rpn_cls: 0.001412  loss_rpn_loc: 0.006508    time: 0.3536  last_time: 0.3117  data_time: 0.0045  last_data_time: 0.0121   lr: 1.9739e-09  max_mem: 1662M\n",
      "\u001b[32m[03/04 17:39:52 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:05:52 (0.3537 s / it)\n",
      "\u001b[32m[03/04 17:39:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:06:57 (0:01:04 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:39:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:39:52 d2.data.datasets.coco]: \u001b[0mLoaded 384 images in COCO format from validation.json\n",
      "\u001b[32m[03/04 17:39:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/04 17:39:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/04 17:39:52 d2.data.common]: \u001b[0mSerializing 384 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:39:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.21 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:39:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[03/04 17:39:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 384 batches\n",
      "\u001b[32m[03/04 17:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/384. Dataloading: 0.0013 s/iter. Inference: 0.1393 s/iter. Eval: 0.0142 s/iter. Total: 0.1548 s/iter. ETA=0:00:57\n",
      "\u001b[32m[03/04 17:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 44/384. Dataloading: 0.0013 s/iter. Inference: 0.1383 s/iter. Eval: 0.0142 s/iter. Total: 0.1539 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/04 17:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 78/384. Dataloading: 0.0013 s/iter. Inference: 0.1389 s/iter. Eval: 0.0121 s/iter. Total: 0.1524 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/04 17:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 112/384. Dataloading: 0.0013 s/iter. Inference: 0.1389 s/iter. Eval: 0.0107 s/iter. Total: 0.1510 s/iter. ETA=0:00:41\n",
      "\u001b[32m[03/04 17:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 147/384. Dataloading: 0.0013 s/iter. Inference: 0.1388 s/iter. Eval: 0.0092 s/iter. Total: 0.1494 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/04 17:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 182/384. Dataloading: 0.0013 s/iter. Inference: 0.1387 s/iter. Eval: 0.0080 s/iter. Total: 0.1482 s/iter. ETA=0:00:29\n",
      "\u001b[32m[03/04 17:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 217/384. Dataloading: 0.0013 s/iter. Inference: 0.1387 s/iter. Eval: 0.0074 s/iter. Total: 0.1476 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/04 17:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 251/384. Dataloading: 0.0013 s/iter. Inference: 0.1386 s/iter. Eval: 0.0076 s/iter. Total: 0.1476 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/04 17:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 287/384. Dataloading: 0.0013 s/iter. Inference: 0.1380 s/iter. Eval: 0.0073 s/iter. Total: 0.1466 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/04 17:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 323/384. Dataloading: 0.0013 s/iter. Inference: 0.1376 s/iter. Eval: 0.0068 s/iter. Total: 0.1458 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/04 17:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 359/384. Dataloading: 0.0013 s/iter. Inference: 0.1371 s/iter. Eval: 0.0067 s/iter. Total: 0.1451 s/iter. ETA=0:00:03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "def register_datasets():\n",
    "    register_coco_instances(\"my_dataset_train\", {}, \"train.json\", \"train\")\n",
    "    register_coco_instances(\"my_dataset_val\", {}, \"validation.json\", \"val\")\n",
    "    register_coco_instances(\"my_dataset_test\", {}, \"test.json\", \"test\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from detectron2.solver.build import get_default_optimizer_params\n",
    "from detectron2.solver.build import maybe_add_gradient_clipping\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        \"\"\"\n",
    "        Build an optimizer from config.\n",
    "        \"\"\"\n",
    "        params = get_default_optimizer_params(model)\n",
    "        return maybe_add_gradient_clipping(cfg, torch.optim.AdamW)(\n",
    "            params, \n",
    "            lr=cfg.SOLVER.BASE_LR, \n",
    "            weight_decay=cfg.SOLVER.WEIGHT_DECAY\n",
    "        )\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "def train():\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "    cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00306982\n",
    "    cfg.SOLVER.MAX_ITER = 1000\n",
    "    #cfg.SOLVER.STEPS = (5000, 7500)\n",
    "    cfg.SOLVER.GAMMA = 0.05\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.TEST.EVAL_PERIOD = 500\n",
    "    cfg.SOLVER.BASE_LR = 8e-4\n",
    "    cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "    cfg.SOLVER.WARMUP_ITERS = int(0.2*cfg.SOLVER.MAX_ITER)\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"value\"\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = MyTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "def test():\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(\"output\", \"model_final.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "    cfg.DATASETS.TEST = (\"my_dataset_test\",)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "    inference = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "    print(inference)\n",
    "\n",
    "# Register datasets\n",
    "register_datasets()\n",
    "\n",
    "# Train the model\n",
    "train()\n",
    "\n",
    "# Test the model\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37156238-532f-4802-8a93-09951ff23f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
